{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_vcb = 366549\n",
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/rafael/Documents/Faculdade/ICs/IC Direito/codes/pre-processing/3. Fine-Tuning NER rodando no servidor/Resultados em toda base de SP/utils/tokenizer_100k.json') as f: \n",
    "    data = json.load(f) \n",
    "    tok = tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definindo metricas customizadas\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_pred = tf.cast(K.argmax(y_pred), tf.float32) # transformando o vetor de (None, 150, n_tags) para (None, 150)\n",
    "    macro_recall = 0\n",
    "    y_pred = y_pred[y_true != 0] # retira zero\n",
    "    y_true = y_true[y_true != 0] # retira zero\n",
    "    equals = y_pred[K.equal(y_true,y_pred)]  # calcula os verdadeiros positivos, ignorando o zero\n",
    "    \n",
    "    for i in range(1,n_tags):\n",
    "        equals_positives = equals[equals == i]  \n",
    "        true_positives = K.sum(equals_positives/i) # divide por i, para que os valores se tornem 1\n",
    "\n",
    "        equals_possibles = y_true[K.equal(y_true,K.constant(i))]/i\n",
    "        possible_positives = K.sum(equals_possibles)\n",
    "\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        macro_recall = macro_recall + recall\n",
    "\n",
    "    macro_recall = macro_recall/(n_tags-1)  \n",
    "\n",
    "    return macro_recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = tf.cast(K.argmax(y_pred), tf.float32) # trannsformando o vetor de (None, 150, n_tags) para (None, 150)\n",
    "    macro_precision = 0\n",
    "    y_pred = y_pred[y_true != 0] # retira zero\n",
    "    y_true = y_true[y_true != 0] # retira zero\n",
    "    equals = y_true[K.equal(y_true,y_pred)]  # calcula os verdadeiros positivos, ignorando o zero\n",
    "    \n",
    "    for i in range(1,n_tags):\n",
    "        equals_positives = equals[equals == i]  \n",
    "        true_positives = K.sum(equals_positives/i) # divide por i, para que os valores se tornem 1\n",
    "\n",
    "        equals_pred_possibles = y_pred[K.equal(y_pred,K.constant(i))]/i\n",
    "        predicted_positives = K.sum(equals_pred_possibles)\n",
    "\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        macro_precision = macro_precision + precision\n",
    "\n",
    "    macro_precision = macro_precision/(n_tags-1)\n",
    "\n",
    "    return macro_precision\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_metrics = {\"recall\": recall,\"precision\": precision, \"macro_f1\": macro_f1}\n",
    "model = tf.keras.models.load_model(\n",
    "    '/home/rafael/Documents/Faculdade/ICs/IC Direito/codes/pre-processing/3. Fine-Tuning NER rodando no servidor/Resultados em toda base de SP/SP_TOTAL_1EPOCH.h5',\n",
    "    custom_objects=custom_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "são_paulo_df = pd.read_json('/home/rafael/Documents/Faculdade/ICs/IC Direito/codes/pre-processing/SP_PROCESSO_E_ASSUNTO_FEITOS_BCKPV2.json')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['0042934-50.2012.8.26.0196 (196.01.2012.042934-1/000000-000) Nº Ordem: 002792/2012 - Divórcio Litigioso - Dissolução - N. M. V. S. X R. D. S. - Expeça-se certidão de honorários (R$654,75 - cód 203) e arquivem-se os autos. Intimem-se. Ciência ao Ministério Público. - ADV SILVANA DE ANDRADE PRADO OAB/SP 175220 - ADV NILCILENE REIS MAXIMIANO DO NASCIMENTO OAB/SP 182011']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "são_paulo_sample = [são_paulo_df.loc[114,'Conteúdo']]\n",
    "são_paulo_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       0    1   2   3   4     5     6   7   8       9   ...      55  56  \\\n",
       "0  180020  363  58  15  17  1721  1451  51  58  180021  ...  120818  18   \n",
       "\n",
       "       57   58     59  60    61  62  63      64  \n",
       "0  180023  890  12733  98  1180  10  11  180024  \n",
       "\n",
       "[1 rows x 65 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>180020</td>\n      <td>363</td>\n      <td>58</td>\n      <td>15</td>\n      <td>17</td>\n      <td>1721</td>\n      <td>1451</td>\n      <td>51</td>\n      <td>58</td>\n      <td>180021</td>\n      <td>...</td>\n      <td>120818</td>\n      <td>18</td>\n      <td>180023</td>\n      <td>890</td>\n      <td>12733</td>\n      <td>98</td>\n      <td>1180</td>\n      <td>10</td>\n      <td>11</td>\n      <td>180024</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 65 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "são_paulo_sample_tokenized = tok.texts_to_sequences(são_paulo_sample)\n",
    "pd.DataFrame(são_paulo_sample_tokenized[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0    1    2    3    4     5     6    7    8       9    ...  140  141  \\\n",
       "0  180020  363   58   15   17  1721  1451   51   58  180021  ...    0    0   \n",
       "\n",
       "   142  143  144  145  146  147  148  149  \n",
       "0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[1 rows x 150 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>140</th>\n      <th>141</th>\n      <th>142</th>\n      <th>143</th>\n      <th>144</th>\n      <th>145</th>\n      <th>146</th>\n      <th>147</th>\n      <th>148</th>\n      <th>149</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>180020</td>\n      <td>363</td>\n      <td>58</td>\n      <td>15</td>\n      <td>17</td>\n      <td>1721</td>\n      <td>1451</td>\n      <td>51</td>\n      <td>58</td>\n      <td>180021</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 150 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "são_paulo_sample_tokenized_padded = pad_sequences(maxlen=max_len,\n",
    "                                    sequences=são_paulo_sample_tokenized,\n",
    "                                    padding=\"post\",\n",
    "                                    truncating=\"post\")\n",
    "pd.DataFrame(são_paulo_sample_tokenized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_são_paulo_sample_tokenized_padded = model(são_paulo_sample_tokenized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 0042934\n1 50\n1 2012\n1 8\n1 26\n1 0196\n1 196\n1 01\n1 2012\n1 042934\n1 1\n1 000000\n1 000\n1 Nº\n1 Ordem\n1 002792\n1 2012\n14 Divórcio\n2 Litigioso\n13 Dissolução\n1 N\n1 M\n1 V\n1 S\n1 X\n1 R\n1 D\n1 S\n1 Expeça\n1 se\n1 certidão\n1 de\n1 honorários\n1 R$654\n1 75\n1 cód\n1 203\n1 e\n1 arquivem\n1 se\n1 os\n1 autos\n1 Intimem\n1 se\n1 Ciência\n1 ao\n1 Ministério\n1 Público\n1 ADV\n1 SILVANA\n1 DE\n1 ANDRADE\n1 PRADO\n1 OAB\n1 SP\n1 175220\n1 ADV\n1 NILCILENE\n1 REIS\n1 MAXIMIANO\n1 DO\n1 NASCIMENTO\n1 OAB\n1 SP\n1 182011\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(predicted_são_paulo_sample_tokenized_padded[0]):\n",
    "    if (i < len(são_paulo_sample_tokenized[0])): \n",
    "        print(np.argmax(p),tok.index_word[são_paulo_sample_tokenized[0][i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bem_Agro_env",
   "language": "python",
   "name": "bem_agro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}